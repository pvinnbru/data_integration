{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Connection string\n",
    "connection_string = \"postgresql://postgres.svsobttfvdpdxpiwjeqg:z36ow70ANRJB5GHa@aws-0-eu-central-1.pooler.supabase.com:6543/postgres\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Load tables from the database\n",
    "dive_sites = pd.read_sql(\"SELECT * FROM dive_site\", con=engine)\n",
    "occurrences = pd.read_sql(\"SELECT * FROM occurrence\", con=engine)\n",
    "categories = pd.read_sql(\"SELECT * FROM dive_site_category\", con=engine)\n",
    "categories_per_dive_site = pd.read_sql(\"SELECT * FROM categories_per_dive_site\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  dive_site_id   region  cluster  rating\n",
      "0      304          4079    Libya        5       3\n",
      "1      304          1348  Denmark        5       4\n",
      "5      143          1773   Turkey        0       4\n",
      "6      143          3757   Turkey        0       4\n",
      "7      143          1686   Turkey        0       3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming dive_sites, categories, categories_per_dive_site, and occurrences are already loaded\n",
    "# Preprocessing dive sites table\n",
    "dive_sites[\"lat\"] = pd.to_numeric(dive_sites[\"lat\"], errors=\"coerce\")\n",
    "dive_sites[\"long\"] = pd.to_numeric(dive_sites[\"long\"], errors=\"coerce\")\n",
    "dive_sites[\"max_depth\"] = pd.to_numeric(dive_sites[\"max_depth\"], errors=\"coerce\")\n",
    "\n",
    "# Merge categories and occurrences\n",
    "category_mapping = categories_per_dive_site.merge(categories, left_on=\"dive_site_category_id\", right_on=\"id\", how=\"left\")\n",
    "dive_site_categories = category_mapping.groupby(\"dive_site_id\")[\"name\"].apply(list).reset_index()\n",
    "dive_sites = dive_sites.merge(dive_site_categories, left_on=\"id\", right_on=\"dive_site_id\", how=\"left\")\n",
    "\n",
    "occurrence_mapping = occurrences.groupby(\"dive_site_id\")[\"animal_id\"].apply(list).reset_index()\n",
    "dive_sites = dive_sites.merge(occurrence_mapping, left_on=\"id\", right_on=\"dive_site_id\", how=\"left\")\n",
    "\n",
    "# Vectorize description\n",
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "description_vectors = tfidf.fit_transform(dive_sites[\"description\"].fillna(\"\")).toarray()\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "geo_features = scaler.fit_transform(dive_sites[[\"max_depth\"]].fillna(0))\n",
    "\n",
    "# Encode categorical data\n",
    "categories_encoded = pd.get_dummies(dive_sites[\"name\"].explode()).groupby(level=0).sum()\n",
    "animals_encoded = pd.get_dummies(dive_sites[\"animal_id\"].explode()).groupby(level=0).sum()\n",
    "\n",
    "# Combine features for clustering\n",
    "features = np.hstack([geo_features, description_vectors, categories_encoded, animals_encoded])\n",
    "\n",
    "# Perform clustering\n",
    "kmeans = KMeans(n_clusters=8, random_state=1)\n",
    "dive_sites[\"cluster\"] = kmeans.fit_predict(features)\n",
    "\n",
    "# Generate synthetic user data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of users and records\n",
    "num_users = 400\n",
    "num_records = 4000\n",
    "\n",
    "# Define user preferences\n",
    "regions = dive_sites[\"region\"].dropna().unique()\n",
    "animals = occurrences[\"animal_id\"].dropna().unique()\n",
    "dive_types = categories[\"name\"].dropna().unique()\n",
    "clusters = dive_sites[\"cluster\"].unique()  # Available clusters\n",
    "\n",
    "user_preferences = []\n",
    "for user_id in range(1, num_users + 1):\n",
    "    preferred_regions = np.random.choice(regions, size=np.random.randint(2, 4), replace=False).tolist()\n",
    "    preferred_animals = np.random.choice(animals, size=np.random.randint(2, 4), replace=False).tolist()\n",
    "    preferred_types = np.random.choice(dive_types, size=np.random.randint(2, 4), replace=False).tolist()\n",
    "    preferred_clusters = np.random.choice(clusters, size=np.random.randint(2, 3), replace=False).tolist()  # Add cluster preferences\n",
    "    user_preferences.append({\n",
    "        \"user_id\": user_id,\n",
    "        \"preferred_regions\": preferred_regions,\n",
    "        \"preferred_animals\": preferred_animals,\n",
    "        \"preferred_types\": preferred_types,\n",
    "        \"preferred_clusters\": preferred_clusters,  # Store preferred clusters\n",
    "    })\n",
    "    \n",
    "pd.DataFrame(user_preferences).to_csv('../preferences.csv')\n",
    "\n",
    "user_ratings_data = []\n",
    "\n",
    "import random\n",
    "\n",
    "# Generate synthetic data for multiple trips per user\n",
    "for _ in range(num_records):\n",
    "    user = np.random.choice(user_preferences)\n",
    "    num_trips = np.random.randint(1, 15)\n",
    "    visited_sites = set()  # Track visited dive sites for the user\n",
    "    \n",
    "    for trip_num in range(num_trips):\n",
    "        trip_region = np.random.choice(user[\"preferred_regions\"]+[np.random.choice(dive_types)])\n",
    "        region_filter = dive_sites[dive_sites[\"region\"] == trip_region]\n",
    "        cluster_filter = region_filter[region_filter[\"cluster\"].isin(user[\"preferred_clusters\"]+[np.random.choice(clusters)])]\n",
    "        trip_sites = cluster_filter if not cluster_filter.empty else region_filter\n",
    "        \n",
    "        num_dives = np.random.randint(2, 24)\n",
    "        num_dives = min(num_dives, len(trip_sites))\n",
    "        if num_dives == 0:\n",
    "            continue\n",
    "        \n",
    "        selected_sites = trip_sites.sample(n=num_dives, replace=False) if not trip_sites.empty else region_filter.sample(n=num_dives, replace=False)\n",
    "        \n",
    "        for _, dive_site in selected_sites.iterrows():\n",
    "            # Neutral rating base\n",
    "            rating = 2.0\n",
    "            \n",
    "            # Adjust rating for matching region\n",
    "            if dive_site[\"region\"] in user[\"preferred_regions\"]:\n",
    "                rating += np.random.uniform(0.3,1)\n",
    "            else:\n",
    "                rating -= np.random.uniform(0,0.3)\n",
    "            \n",
    "            # Adjust rating for matching cluster\n",
    "            if dive_site[\"cluster\"] in user[\"preferred_clusters\"]:\n",
    "                rating += np.random.uniform(0.3,1)\n",
    "            else:\n",
    "                rating -= np.random.uniform(0,0.3)\n",
    "            \n",
    "            # Matching animals\n",
    "            dive_site_animals = dive_site[\"animal_id\"] if isinstance(dive_site[\"animal_id\"], list) else []\n",
    "            matching_animals = set(user[\"preferred_animals\"]) & set(dive_site_animals)\n",
    "            rating += len(matching_animals) * 0.3\n",
    "            \n",
    "            if len(matching_animals)==0:\n",
    "                rating -= np.random.uniform(0,1)\n",
    "            \n",
    "            # Matching dive types\n",
    "            dive_site_types = dive_site[\"name\"] if isinstance(dive_site[\"name\"], list) else []\n",
    "            matching_types = set(user[\"preferred_types\"]) & set(dive_site_types)\n",
    "            rating += len(matching_types) * 0.3\n",
    "            \n",
    "            if len(matching_types)==0:\n",
    "                rating -= np.random.uniform(-2,-0.5)\n",
    "            \n",
    "            # Add subtle random noise\n",
    "            rating += np.random.uniform(-0.5, 0.5)\n",
    "            \n",
    "            # Bound the rating between 1 and 5\n",
    "            rating = max(min(round(rating), 5), 1)\n",
    "            \n",
    "            rating = round(rating,0)\n",
    "            \n",
    "            # Add entry to ratings data\n",
    "            user_ratings_data.append({\n",
    "                \"user_id\": user[\"user_id\"],\n",
    "                \"dive_site_id\": int(dive_site[\"id\"]),\n",
    "                \"region\": dive_site[\"region\"],\n",
    "                \"cluster\": dive_site[\"cluster\"],\n",
    "                \"rating\": rating,\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "user_ratings_df = pd.DataFrame(user_ratings_data)\n",
    "\n",
    "# Drop duplicates for unique user-dive site combinations\n",
    "user_ratings_df = user_ratings_df.drop_duplicates(subset=[\"user_id\", \"dive_site_id\"])\n",
    "\n",
    "# Display a sample of the generated dataset\n",
    "print(user_ratings_df.head())\n",
    "\n",
    "# Save to CSV for further processing\n",
    "user_ratings_df.to_csv(\"../user_ratings_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assume user_ratings_data is a list of dictionaries\n",
    "# Convert it into a DataFrame for easier manipulation\n",
    "user_ratings_df\n",
    "\n",
    "# Plot a histogram of ratings\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(user_ratings_df[\"rating\"], bins=20, kde=True, color=\"skyblue\")\n",
    "plt.title(\"Distribution of Dive Site Ratings\", fontsize=16)\n",
    "plt.xlabel(\"Rating\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Plot a boxplot of ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=user_ratings_df[\"rating\"], color=\"lightgreen\")\n",
    "plt.title(\"Boxplot of Dive Site Ratings\", fontsize=16)\n",
    "plt.xlabel(\"Rating\", fontsize=14)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Print basic statistics\n",
    "mean_rating = user_ratings_df[\"rating\"].mean()\n",
    "median_rating = user_ratings_df[\"rating\"].median()\n",
    "std_rating = user_ratings_df[\"rating\"].std()\n",
    "\n",
    "print(f\"Mean Rating: {mean_rating:.2f}\")\n",
    "print(f\"Median Rating: {median_rating:.2f}\")\n",
    "print(f\"Standard Deviation of Ratings: {std_rating:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
